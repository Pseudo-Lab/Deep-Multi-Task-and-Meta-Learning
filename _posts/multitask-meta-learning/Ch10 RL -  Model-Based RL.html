

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Lecture 10. Model-Based RL &#8212; 멀티태스크/메타러닝 초읽기</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_posts/multitask-meta-learning/Ch10 RL -  Model-Based RL';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Lecture 11. Meta RL: Adaptable Models &amp; Policies" href="Ch11%20RL%20-%20Meta%20RL%3A%20Adaptable%20Models%20%26%20Policies.html" />
    <link rel="prev" title="Lecture 9. Reinforcemeht Learning : A Primer, Multi-Task, Goal-Conditioned" href="Ch09%20RL%20-%20A%20Primer%2C%20Multi-Task%2C%20Goal-Conditioned.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/PseudoLab_logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/PseudoLab_logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    인트로
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Multi-Task &amp; Meta Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Ch03%20RL%20-%20Optimization-based-meta-learning/index.html">Lecture 4. Optimization-based Meta Learning (MAML)</a></li>
<li class="toctree-l1"><a class="reference internal" href="Ch06%20RL%20-%20Non_Parametric_Few_Shot_Learning.html">Lecture 6. Non-Parametric Few-Shot Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Ch09%20RL%20-%20A%20Primer%2C%20Multi-Task%2C%20Goal-Conditioned.html">Lecture 9. Reinforcemeht Learning : A Primer, Multi-Task, Goal-Conditioned</a></li>

<li class="toctree-l1 current active"><a class="current reference internal" href="#">Lecture 10. Model-Based RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="Ch11%20RL%20-%20Meta%20RL%3A%20Adaptable%20Models%20%26%20Policies.html">Lecture 11. Meta RL: Adaptable Models &amp; Policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="Ch12%20RL%20-%20MetaRL%3ALearning%20to%20explore/index.html">Lecture 12. Meta-RL: Learning to explore</a></li>
<li class="toctree-l1"><a class="reference internal" href="Ch15%20RL%20-%20Lifelong%20Learning.html">Lecture 15. Lifelong Learning</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/Deep-Multi-Task-and-Meta-Learning" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/Deep-Multi-Task-and-Meta-Learning/issues/new?title=Issue%20on%20page%20%2F_posts/multitask-meta-learning/Ch10 RL -  Model-Based RL.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/_posts/multitask-meta-learning/Ch10 RL -  Model-Based RL.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lecture 10. Model-Based RL</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">개요</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">문제점</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-task-rl">Multi-task RL</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#latent-representation">Latent Representation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">참고 자료</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="lecture-10-model-based-rl">
<h1>Lecture 10. Model-Based RL<a class="headerlink" href="#lecture-10-model-based-rl" title="Permalink to this heading">#</a></h1>
<blockquote>
<div><p>Organization: 가짜연구소 (Pseudo Lab)<br />
Editor: <a class="reference external" href="https://github.com/howsmyanimeprofilepicture">이홍규</a><br/>
강의 자료: <a class="reference external" href="http://cs330.stanford.edu/fall2020/slides/cs330_mbrl_2020.pdf">CS330 2020 Fall</a><br />
강의 영상: <a class="reference external" href="https://youtu.be/LGhVQ3NB9h4">Youtube</a></p>
</div></blockquote>
<section id="id1">
<h2>개요<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Model-based RL의 주된 모티베이션은 <strong>충분한 양의 데이터 확보</strong>입니다.</p></li>
<li><p>실제 시스템을 동작함해서 얻은 데이터는 품질은 완벽하지만, 그 양이 모델을 충분히 generalization하기에는 부족할 수밖에 없습니다.</p></li>
</ul>
<div class="important admonition">
<p class="admonition-title">Example</p>
<p>예를 들어 참다랑어 스시를 만드는 로봇을 구현한다고 가정합시다. 고추냉이가 너무 들어가서 먹으면서 눈물을 쏟는 스시도 있을 것이고, 밥이 너무 많이 들어가고 참다랑어는 눈꼽만큼 올려져 있는 스시도 있을 것입니다. 모든 형태의 스시(state)를 실제 로봇을 동작해서 표현하려고 한다면, 그건 로봇도 힘들고, 수 많은 참다랑어가 소비되어야 합니다.</p>
</div>
<ul class="simple">
<li><p>따라서 <mark>실제 환경의 transition dynamic ( <span class="math notranslate nohighlight">\(p(s'|s,a)\)</span> ) 을 모델 ( <span class="math notranslate nohighlight">\(f_\phi(s,a)\)</span> )을 통해 시뮬레이션</mark>하고, 이를 통해 데이터의 부족을 해결해보자는 접근방법이 <strong>Model-based RL</strong>이라고 할 수 있습니다.</p></li>
<li><p>다이나믹 모델은 stochastic하게 구현될 수도 deterministic하게 구현될 수도 있습니다.</p></li>
<li><p>모델은 일반적으로 아래와 같이 일반적인 supervised learning의 형태로 fitting됩니다.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathcal D = \{(s_i, a_i, s'_i)|i=1,~\cdots,~N~\}\\
\min_\phi \sum_i ||f_\phi(s_i, a_i) - s_i'||^2
\end{split}\]</div>
<ul class="simple">
<li><p>여기서 모델은 현재 state와 action을 전달받고 다음 state의 distribution을 예측하도록 피팅됩니다.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
f_\phi(s, a) = p(s'|s,a)
\]</div>
</section>
<section id="id2">
<h2>문제점<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<p>먼저 Model-Based RL은 다음과 같이 동작합니다.</p>
<div class="note admonition">
<p class="admonition-title">Peudo-Code</p>
<ol class="arabic simple">
<li><p>어떠한 폴리시(e.g. random policy)를 통해 실제 환경으로부터 데이터를 수집합니다. <span class="math notranslate nohighlight">\(\mathcal D = \{(o_i, a_i, o'_i)\}\)</span></p></li>
<li><p>해당 데이터를 통해 모델을 피팅합니다. <span class="math notranslate nohighlight">\(s' = f_\phi(s,a)\)</span>.</p></li>
<li><p>해당 모델을 통해 <span class="math notranslate nohighlight">\(f_\phi(s, a)\)</span>, 최적의 액션 시퀀스를 산출합니다.</p></li>
</ol>
</div>
<p><img alt="slide 1" src="../../_images/lec10_1.png" /></p>
<p><a class="reference external" href="https://youtu.be/LGhVQ3NB9h4?list=PLoROMvodv4rOxuwpC_raecBCd5Jf54lEa&amp;t=1749">source</a></p>
<ul class="simple">
<li><p>하지만 아무리 실제환경을 잘 피팅했다고 해도 <mark>모델에는 어느 정도의 오차가 존재합니다. </mark></p></li>
<li><p>그리고 액션이 길어질수록 이 에러들이 쌓이면서 나중에는 무시하지 못할 수준이 될 수 있습니다.</p></li>
<li><p>이와 같은 문제의 경우, 모델이 생성한 데이터를 다시 모델 피팅에 사용함으로써 어느 정도 완화할 수 있습니다.</p></li>
<li><p>해당 알고리즘은 <strong>MPC</strong>(model-predictive control)라고 불립니다.</p></li>
</ul>
<p><img alt="slide 2" src="../../_images/lec10_2.png" /></p>
<p><a class="reference external" href="https://youtu.be/LGhVQ3NB9h4?list=PLoROMvodv4rOxuwpC_raecBCd5Jf54lEa&amp;t=1913">source</a></p>
<div class="note admonition">
<p class="admonition-title">Peudo-Code</p>
<ol class="arabic simple">
<li><p>어떠한 폴리시(e.g. random policy)를 통해 실제 환경으로부터 데이터를 수집합니다. <span class="math notranslate nohighlight">\(\mathcal D = \{(o_i, a_i, o'_i)\}\)</span></p></li>
<li><p>해당 데이터를 통해 모델을 피팅합니다. <span class="math notranslate nohighlight">\(s' = f_\phi(s,a)\)</span>.</p></li>
<li><p>해당 모델을 통해 <span class="math notranslate nohighlight">\(f_\phi(s, a)\)</span>, 최적의 액션 시퀀스를 산출합니다.</p></li>
<li><p>산출된 최적의 액션 시퀀스에서 첫번째 액션만을 실행하고 나머지는 버립니다.</p></li>
<li><p>액션 실행 결과로 얻은 데이터 <span class="math notranslate nohighlight">\((s,a,s')\)</span>를 데이터셋에 추가합니다.</p></li>
<li><p>2번으로 돌아갑니다.</p></li>
</ol>
</div>
</section>
<section id="multi-task-rl">
<h2>Multi-task RL<a class="headerlink" href="#multi-task-rl" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>강화학습 태스크는 다음과 같이 정의됩니다.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\underbrace{\mathcal T_i}_\text{task} 
\triangleq \{\mathcal S_i,~
\mathcal A_i,~
p_i(s_1),~
p_i(s'|s,a),~
r_i(s,a)\}
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathcal S_i\)</span> : state space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal A_i\)</span> : action space</p></li>
<li><p><span class="math notranslate nohighlight">\(p_i(s_1)\)</span> : distribution of initial states</p></li>
<li><p><span class="math notranslate nohighlight">\(p_i(s'|s,a)\)</span> : transition dynamics or transition probability</p></li>
<li><p><span class="math notranslate nohighlight">\(r_i(s,a)\)</span> : reward</p></li>
<li><p>하지만 많은 경우에서, 오직 <mark><strong>리워드</strong>만이 태스크를 구분하는 요소</mark>가 되곤 합니다.</p></li>
<li><p>예를 들어 다양한 태스크를 수행하는 로봇을 만든다고 했을 때, 해당 로봇이 가질 수 있는 State와 Action은 태스크와 무관하게 동일할 것입니다.</p></li>
<li><p>하지만 해당 로봇은 태스크에 따라 리워드는 당연히 다를 것입니다.</p></li>
</ul>
<div class="important admonition">
<p class="admonition-title">Example</p>
<p>예를 들어 스테이크를 굽는 로봇을 구현한다고 가정합시다. 스테이크가 완전히 속까지 익을 정도로 구어졌다면, 레어로 굽는 태스크에서는 리워드가 마이너스 혹은 0이겠지만, 웰던으로 굽는 태스크에서는 좋은 리워드를 받을 것입니다.</p>
</div>
<p><img alt="slide 3" src="../../_images/lec10_3.png" /></p>
<p><a class="reference external" href="https://youtu.be/LGhVQ3NB9h4?list=PLoROMvodv4rOxuwpC_raecBCd5Jf54lEa&amp;t=2006">source</a></p>
<ul class="simple">
<li><p>각 태스크별로 reward function의 형태를 알고 있는 경우, 해당 reward function에 기반해, 해당 태스크에 맞게, 액션을 플래닝하면 될 것입니다.</p></li>
<li><p>하지만 태스크에 따른 reward function의 형태를 모를 경우, 우리는 태스크 별 reward function을 추정해야 할 것입니다.</p></li>
<li><p>이 때 앞서 배웠던 Multi-task Learning, 그리고 Meta Learning 방법론이 사용될 수 있습니다.</p></li>
<li><p>위 이미지에 Meta Learning을 통해 reward function을 학습시키는 어프로치가 소개되어 있는데, 2개의 Positive example만 주어진 채로, (state, action) 튜플 4개에 대해 binary한 reward를 추정하도록 훈련시키고 있습니다.</p></li>
</ul>
</section>
<section id="latent-representation">
<h2>Latent Representation<a class="headerlink" href="#latent-representation" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Model-based RL에서 자주 사용되는 어프로치 중에 하나는 observation을 상대적으로 더 낮은 차원의 latent space로 임베딩하는 것입니다.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
s = g(o)
\]</div>
<ul class="simple">
<li><p>알고리즘을 살펴보면 다음과 같습니다.</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title">Peudo-Code</p>
<ol class="arabic simple">
<li><p>어떠한 폴리시(e.g. random policy)를 통해 실제 환경으로부터 데이터를 모읍니다. <span class="math notranslate nohighlight">\(\mathcal D = \{(o_i, a_i, o'_i)\}\)</span></p></li>
<li><p>인코더(<span class="math notranslate nohighlight">\(g\)</span>)를 통해 observation들을 임베딩하고 — <span class="math notranslate nohighlight">\(s = g(o)\)</span> — 임베딩된 state들을 기반으로 모델을 피팅합니다. — <span class="math notranslate nohighlight">\(s' = f_\phi(s,a)\)</span>.</p></li>
<li><p>모델(<span class="math notranslate nohighlight">\(f_\phi(s, a)\)</span>)을 통해 최적의 액션 시퀀스를 산출합니다.</p></li>
<li><p>(추가적으로 MPC등이 도입될 수도 있을 것입니다.)</p></li>
</ol>
</div>
<ul class="simple">
<li><p>이러한 어프로치에서 우리는 리워드를 다음과 같이 정의할 수 있습니다.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
r(o_i, a_i) = -||g(o_i') - g(o_\text{goal})||^2
\]</div>
<div class="math notranslate nohighlight">
\[
r(s_i, a_i) = -||s'_i - s_\text{goal}||^2
\]</div>
<ul class="simple">
<li><p>주의할 점은, 임베딩된 스테이트가 정보를 잘 표현하고, 원래의 이미지로의 reconstruction도 잘 된다해도, <mark>반드시 state간의 L2 distance가 observation간의 유사도를 표현한다고 보장할 수는 없다</mark>는 것입니다.</p></li>
<li><p>따라서 이와 같이 L2-distnace를 기반으로 리워드를 정의할 경우, L2-distance가 스테이트 간의 유사도를 표현할 수 있도록 옵저베이션을 임베딩해야 합니다.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}
s_i \leftarrow g_\text{enc}(o_i;~\theta_\text{enc}) \\
\hat o_i \leftarrow g_\text{dec}(s_i;~\theta_\text{dec}) \\\end{split}\\\begin{split}\theta_\text{enc} \leftarrow \arg\min_{\theta_\text{enc}} 
\sum_i||\hat o_i -o_i||^2 \\
\theta_\text{dec} \leftarrow \arg\min_{\theta_\text{dec}} 
\sum_i||\hat o_i -o_i||^2
\end{split}\end{aligned}\end{align} \]</div>
<ul class="simple">
<li><p>또한 우리는 <strong>Reconstruction Error</strong>를 고려해서, 모델뿐만이 아니라 옵저베이션을 임베딩하는 <mark><strong>인코더</strong>와 <strong>디코더</strong>도 피팅해야합니다.</mark></p></li>
<li><p>단순히 임베딩된 스테이트만을 사용해서 모델을 피팅한다면,</p></li>
<li><p>Encoder가 Trivial Solution —e.g., 모든 observation을 zero vector로 임베딩 — 을 산출할 수 있기 때문입니다.</p></li>
</ul>
</section>
<section id="id3">
<h2>참고 자료<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Manuel Watter, Jost Tobias Springenberg, Joschka Boedecker, and Martin Riedmiller (<em>2015</em>). <a class="reference external" href="https://arxiv.org/abs/1506.07365">“Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images”</a>.</p></li>
<li><p>Chelsea Finn, Xin Yu Tan, Yan Duan, Trevor Darrell, Sergey Levine, Pieter Abbeel (2015). <a class="reference external" href="https://arxiv.org/abs/1509.06113">“Deep Spatial Autoencoders for Visuomotor Learning”</a>.</p></li>
<li><p>Michael Janner (2019). <a class="reference external" href="https://bair.berkeley.edu/blog/2019/12/12/mbpo/">“Model-Based Reinforcement Learning: Theory and Practice”</a>.</p></li>
<li><p>Ruben Villegas, Arkanath Pathak, Harini Kannan, Dumitru Erhan, Quoc V. Le, and Honglak Lee (2019). <a class="reference external" href="https://arxiv.org/abs/1911.01655">“High Fidelity Video Prediction with Large Stochastic Recurrent Neural Networks”</a>.</p></li>
<li><p>Chelsea Finn, Sergey Levine (2016). <a class="reference external" href="https://arxiv.org/abs/1610.00696">“Deep Visual Foresight for Planning Robot Motion”</a></p></li>
<li><p>Chelsea Finn (2020). <a class="reference external" href="https://www.youtube.com/watch?v=LGhVQ3NB9h4&amp;list=PLoROMvodv4rOxuwpC_raecBCd5Jf54lEa&amp;t=2006s">“Stanford CS330:Multi-task and Meta Learning | 2020 | Lecture 10 - Model-Based Reinforcement Learning”</a> (YouTube).</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./_posts/multitask-meta-learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="Ch09%20RL%20-%20A%20Primer%2C%20Multi-Task%2C%20Goal-Conditioned.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Lecture 9. Reinforcemeht Learning : A Primer, Multi-Task, Goal-Conditioned</p>
      </div>
    </a>
    <a class="right-next"
       href="Ch11%20RL%20-%20Meta%20RL%3A%20Adaptable%20Models%20%26%20Policies.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lecture 11. Meta RL: Adaptable Models &amp; Policies</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">개요</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">문제점</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-task-rl">Multi-task RL</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#latent-representation">Latent Representation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">참고 자료</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By 가짜연구소 멀티태스크/메타러닝 초읽기 팀
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>